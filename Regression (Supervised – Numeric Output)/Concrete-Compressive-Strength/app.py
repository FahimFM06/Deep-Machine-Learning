# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j4gddxuJR00dxf3NQl_4mggSW8rYPNyD
"""

import json
import numpy as np
import pandas as pd
import streamlit as st
import lightgbm as lgb
import matplotlib.pyplot as plt

from sklearn.inspection import PartialDependenceDisplay
import shap
from lime.lime_tabular import LimeTabularExplainer

from preprocessing import build_features


st.set_page_config(page_title="Concrete Strength Predictor", layout="wide")
st.title("Concrete Compressive Strength Prediction (LightGBM)")

# -----------------------------
# Load model and feature names
# -----------------------------
@st.cache_resource
def load_artifacts():
    model = lgb.Booster(model_file="lightgbm_best_model.txt")
    with open("feature_names.json", "r") as f:
        feature_names = json.load(f)
    return model, feature_names

model, FEATURE_NAMES = load_artifacts()


def align_features(df):
    df = df.copy()
    for col in FEATURE_NAMES:
        if col not in df.columns:
            df[col] = 0.0
    return df[FEATURE_NAMES]


# -----------------------------
# Sidebar inputs
# -----------------------------
st.sidebar.header("Concrete Mix Inputs")

cement = st.sidebar.number_input("Cement", 0.0, 1000.0, 300.0)
slag = st.sidebar.number_input("Blast Furnace Slag", 0.0, 500.0, 0.0)
fly_ash = st.sidebar.number_input("Fly Ash", 0.0, 500.0, 0.0)
water = st.sidebar.number_input("Water", 0.0, 300.0, 180.0)
superplasticizer = st.sidebar.number_input("Superplasticizer", 0.0, 50.0, 0.0)
coarse = st.sidebar.number_input("Coarse Aggregate", 0.0, 1500.0, 950.0)
fine = st.sidebar.number_input("Fine Aggregate", 0.0, 1500.0, 750.0)
age = st.sidebar.number_input("Age (days)", 1.0, 365.0, 28.0)

raw_input = pd.DataFrame([{
    "cement": cement,
    "blast_furnace_slag": slag,
    "fly_ash": fly_ash,
    "water": water,
    "superplasticizer": superplasticizer,
    "coarse_aggregate": coarse,
    "fine_aggregate": fine,
    "age": age
}])


tab1, tab2, tab3 = st.tabs(["Prediction", "Batch Prediction", "Explainable AI"])


# -----------------------------
# Tab 1: Single Prediction
# -----------------------------
with tab1:
    engineered = build_features(raw_input)
    X_one = align_features(engineered)

    pred = model.predict(X_one)[0]
    st.metric("Predicted Compressive Strength", f"{pred:.2f}")

    with st.expander("Engineered Features"):
        st.dataframe(X_one)


# -----------------------------
# Tab 2: Batch Prediction
# -----------------------------
with tab2:
    uploaded = st.file_uploader("Upload CSV", type=["csv"])
    if uploaded:
        df = pd.read_csv(uploaded)

        required = [
            "cement","blast_furnace_slag","fly_ash","water",
            "superplasticizer","coarse_aggregate","fine_aggregate","age"
        ]

        if not all(c in df.columns for c in required):
            st.error("CSV missing required columns.")
        else:
            df_feat = build_features(df[required])
            X_batch = align_features(df_feat)
            df["predicted_strength"] = model.predict(X_batch)

            st.dataframe(df.head())
            st.download_button(
                "Download predictions",
                df.to_csv(index=False),
                "predictions.csv",
                "text/csv"
            )


# -----------------------------
# Tab 3: Explainable AI
# -----------------------------
with tab3:
    method = st.selectbox("Choose XAI Method", ["SHAP", "LIME", "PDP/ICE"])

    engineered = align_features(build_features(raw_input))

    if method == "SHAP":
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(engineered)

        shap_exp = shap.Explanation(
            values=shap_values[0],
            base_values=explainer.expected_value,
            data=engineered.iloc[0],
            feature_names=engineered.columns
        )

        fig = plt.figure()
        shap.plots.waterfall(shap_exp, show=False)
        st.pyplot(fig)

    elif method == "LIME":
        explainer = LimeTabularExplainer(
            training_data=engineered.values,
            feature_names=engineered.columns.tolist(),
            mode="regression"
        )

        exp = explainer.explain_instance(
            engineered.iloc[0].values,
            lambda x: model.predict(pd.DataFrame(x, columns=engineered.columns))
        )

        for e in exp.as_list():
            st.write(e)

        st.pyplot(exp.as_pyplot_figure())

    else:
        feature = st.selectbox("Feature", engineered.columns)
        fig, ax = plt.subplots()
        PartialDependenceDisplay.from_estimator(
            model, engineered, [feature], kind="both", ax=ax
        )
        st.pyplot(fig)
